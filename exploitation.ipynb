{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll13abb44Gx5",
        "outputId": "7b76ed18-6ee5-4431-fa00-72bc5f539a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws2vVYXTFgnK",
        "outputId": "da7c3e0d-4c23-4bc5-cf26-d7baccd7d53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 43.4 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 19.3 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 28.8 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=327e7ff749e40c58253f2d317da20b08a9bf1b5efdb8957d82bc43f122b709ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0 torch-geometric-2.0.4 torch-scatter-2.0.9 torch-sparse-0.6.13 torch-spline-conv-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ghuZ7ABPcG6S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import subgraph\n",
        "from torch_geometric.datasets import AmazonProducts\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import ClusterGCNConv, GATConv, SAGEConv, TransformerConv, LayerNorm,GMMConv\n",
        "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
        "import networkx as nx\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfzOoi7dd_7L"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "47SoQUOGcN5N"
      },
      "outputs": [],
      "source": [
        "# dataset = 'Computers'\n",
        "root='./drive/My Drive/dataset'\n",
        "dataset = AmazonProducts(root, transform=T.TargetIndegree())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H0iZkYju_UnK"
      },
      "outputs": [],
      "source": [
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "oLo2mKB7zbJN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35qXClA-b_AC"
      },
      "source": [
        "Given this dataset, a question that might come to mind is whether the frequency of two products being bought together is related with their category.\n",
        "In the follow in Histogram we will figure out whether two items that are more frequetly bought together, are also more likely to belong in the same class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_w1FiyvVFtq"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def same_class(a, b):\n",
        "  return torch.logical_and(a, b).sum() > 0\n",
        "\n",
        "productsCount = np.zeros(10)\n",
        "sameClassCount = np.zeros(10)\n",
        "# Iterate through the first 264339468 edges\n",
        "for edge_index in range(26433946):\n",
        "  freqIndex = math.floor(data.edge_attr[edge_index]*10)\n",
        "  if (freqIndex == 10):\n",
        "    freqIndex = 9\n",
        "\n",
        "  productsCount[freqIndex] +=1\n",
        "  # If they belong in the same class \n",
        "  if same_class(data.y[data.edge_index[0][edge_index]], data.y[data.edge_index[1][edge_index]]):\n",
        "    sameClassCount[freqIndex] +=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lteoVkiQdDtl",
        "outputId": "81253929-582c-4952-9ec4-3e1597607b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.12605997 0.12069533 0.11200213 0.13055347 0.12563538 0.12590081\n",
            " 0.09450767 0.03587444 0.06547619 0.03914141]\n",
            "\n",
            "[2.195344e+06 3.191010e+05 8.255200e+04 2.527700e+04 1.180400e+04\n",
            " 4.718000e+03 2.021000e+03 1.115000e+03 6.720000e+02 7.920000e+02]\n"
          ]
        }
      ],
      "source": [
        "# Divide same class products with products count of each frequency index\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "y = np.nan_to_num(sameClassCount/productsCount)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55_XYKNCjyQ9"
      },
      "source": [
        "We end up with the following graph, where the x axis is the frequency of two products being bought together (divided into 10 bars) and the y axis is the percentage of items that belong in the same category.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "YIojlrx7hHUy",
        "outputId": "028daa1a-7719-4969-94ae-f518af09643c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_xlabel('Frequency of two products being bought together')\n",
        "ax.set_ylabel('Percentage of same category products')\n",
        "langs = ['<0.1', '<0.2', '<0.3', '<0.4', '<0.5', '<0.6', '<0.7', '<0.8', '<0.9', '<=1']\n",
        "ax.bar(langs, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OugtzxBbkcdc"
      },
      "source": [
        "As we see, the items that are frequently bought together, are less likely to belong in the same category. Therefore the edges attribute is not sufficient in order to classify the products, and as a result we certainly need to take advantage of the nodes features."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "YPgm4z6Mz3VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the visualization results, products of the same category are close to each other in the Euclidean space of the node feature. Therefore, we use KNN (K=5) as the baseline, i.e. assign one item with the category that the K nearest items vote."
      ],
      "metadata": {
        "id": "-vZJFrSb1hCo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdRlskrf1yFe"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf = KNeighborsClassifier(n_neighbors=5).fit(data.x[data.train_mask], \n",
        "              data.y[data.train_mask])\n",
        "\n",
        "predict_y = clf.predict(data.x[data.test_mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb_v47NmVjHO",
        "outputId": "ff377943-a170-4426-bbb0-6a86f4e93b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3131168170730656"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1 = f1_score(data.y[data.test_mask].cpu().detach().numpy(), predict_y, average='micro' )\n",
        "f1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also tried RidgeClassifier."
      ],
      "metadata": {
        "id": "plc5LxVb1j8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut5vxsYuV2Qs",
        "outputId": "ba86fca3-c9ba-4aae-99f4-365c9fc5628a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08338830170734325"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "clf = RidgeClassifierCV().fit(data.x[data.train_mask],data.y[data.train_mask])\n",
        "predict_y = clf.predict(data.x[data.test_mask])\n",
        "f1 = f1_score(data.y[data.test_mask].cpu().detach().numpy(), predict_y, average='micro' )\n",
        "f1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network\n",
        "### Graph Sampling\n",
        "\n",
        "The Amazon dataset is too large to do a full-batch training of GNN because GPU memory is limited. Also, in standard SGD, if we sample nodes independently in a mini-batch, sampled nodes tend to be isolated from each other and GNN cannot access to neighboring nodes to aggregate their node features. Therefore, we consider using graph samplers to enable message-passing over small subgraphs in each mini-batch and only the subgraphs need to be loaded on a GPU at a time. \n",
        "\n",
        "Existent methods include neighbor sampling [Hamilton et al. NeurIPS 2017] (https://arxiv.org/abs/1706.02216), Cluster-GCN [Chiang et al. KDD 2019] (https://arxiv.org/abs/1905.07953) and GraphSAINT sampler (https://arxiv.org/abs/1907.04931), because in  the GraphSAINT paper the GraphSAINT sampler outperforms the other two. Specifically, we use the random walk based sampler with walk length 4, batch size 1500, num_steps (The number of iterations per epoch) 5, sample coverage (How many samples per node should be used to compute normalization statistics) 100. "
      ],
      "metadata": {
        "id": "zx1t501z0d1X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yW60YeVL0OwK"
      },
      "outputs": [],
      "source": [
        "\n",
        "tr_loader = GraphSAINTRandomWalkSampler(data, batch_size=1500, walk_length=4,\n",
        "                                     num_steps=5, sample_coverage=100,\n",
        "                                     save_dir=dataset.processed_dir,\n",
        "                                     num_workers=4)\n",
        "test_loader = GraphSAINTRandomWalkSampler(data, batch_size=1500, walk_length=4,\n",
        "                                     num_steps=5, sample_coverage=100,\n",
        "                                     save_dir=dataset.processed_dir,\n",
        "                                     num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition, training and testing"
      ],
      "metadata": {
        "id": "_Bj-8v4c0tZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture we first consider is 3 ClusterGCNConv layers, which is the ClusterGCN graph convolutional operator from [Chiang et al. KDD 2019] ($\\mathbf{X}^{\\prime} = \\left( \\mathbf{\\hat{A}} + \\lambda \\cdot\n",
        "\\textrm{diag}(\\mathbf{\\hat{A}}) \\right) \\mathbf{X} \\mathbf{W}_1 +\n",
        "\\mathbf{X} \\mathbf{W}_2$\n",
        "\n",
        "where $\\mathbf{\\hat{A}} = {(\\mathbf{D} + \\mathbf{I})}^{-1}(\\mathbf{A}+\\mathbf{I})$), with elu (Exponential Linear Unit) as the activation function.\n",
        "\n",
        "Considering the previous knowledge that the category of one item may not have much to do with its neighbors in the graph. Instead, the node feature itself may contain more information about its category. Therefore,  we add residual connection between the convolution layers."
      ],
      "metadata": {
        "id": "uXqV-Xp81PUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A61qM8UekR1"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.nn\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        in_channels = dataset.num_node_features\n",
        "        out_channels = dataset.num_classes\n",
        "\n",
        "        self.conv1 = ClusterGCNConv(in_channels, hidden_channels)\n",
        "        self.lin1 = torch.nn.Linear(in_channels, hidden_channels)\n",
        "        self.conv2 = ClusterGCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.conv3 = ClusterGCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin3 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.conv4 = ClusterGCNConv(hidden_channels, out_channels)\n",
        "        self.lin4 = torch.nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "       \n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
        "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
        "        x = F.elu(self.conv3(x, edge_index) + self.lin3(x))\n",
        "        x = self.conv4(x, edge_index) + self.lin4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(hidden_channels=512).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = total_examples = 0\n",
        "    for batch in tr_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "        criterion_weighted = torch.nn.BCEWithLogitsLoss(weight=batch.node_norm[batch.train_mask].unsqueeze(1), reduction=\"sum\")\n",
        "        loss = criterion_weighted(out[batch.train_mask], batch.y[batch.train_mask, :num_classes].float())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_nodes\n",
        "        total_examples += data.num_nodes\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_f1s = []\n",
        "    val_f1s = []\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "        \n",
        "        pred = out.sigmoid() > 0.5\n",
        "        test_f1 = f1_score(batch.y[batch.test_mask, :num_classes].cpu().detach().numpy(), \n",
        "                      pred[batch.test_mask].cpu().detach().numpy(), average='micro' ) \n",
        "        val_f1 = f1_score(batch.y[batch.val_mask, :num_classes].cpu().detach().numpy(), \n",
        "                      pred[batch.val_mask].cpu().detach().numpy(), average='micro' ) \n",
        "        \n",
        "        test_f1s.append(test_f1)\n",
        "        val_f1s.append(val_f1)\n",
        "    \n",
        "    return np.mean(val_f1s), np.mean(test_f1s)\n",
        "\n",
        "\n",
        "best_val_score, test_score = 0.0, 0.0\n",
        "best_test_score = 0.0\n",
        "for epoch in range(1, 501):\n",
        "    loss = train()\n",
        "    val_f1, te_f1 = test()\n",
        "    if best_val_score < val_f1:\n",
        "      best_val_score = val_f1\n",
        "      test_score = te_f1\n",
        "    if best_test_score < te_f1:\n",
        "      best_test_score = te_f1\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val:{val_f1:.4f}, Test: {te_f1:.4f}')\n",
        "print(best_val_score, test_score)\n",
        "print(best_test_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "GCN_Amazon_Products_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}